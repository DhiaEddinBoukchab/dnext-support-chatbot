{
  "evaluation_metadata": {
    "input_file": "output\\rag_pipeline_results.json",
    "num_samples": 3,
    "metrics": [
      "faithfulness"
    ],
    "note": "Only faithfulness metric used (does not require ground truth)",
    "llm_config": {
      "model": "gpt-4",
      "max_tokens": 4096
    }
  },
  "individual_scores": [
    {
      "sample_id": 0,
      "faithfulness": null
    },
    {
      "sample_id": 1,
      "faithfulness": null
    },
    {
      "sample_id": 2,
      "faithfulness": null
    }
  ],
  "summary": {
    "total_samples": 3,
    "metrics": {
      "faithfulness": {
        "count": 0,
        "mean": null,
        "median": null,
        "std": null,
        "min": null,
        "max": null
      }
    }
  }
}