"""
Script complet de validation et r√©indexation avec chunking par s√©parateurs
√Ä ex√©cuter avant de d√©marrer le chatbot
"""

import sys
from pathlib import Path
import re

sys.path.insert(0, str(Path(__file__).parent))

from config import Config
from src.embeddings import EmbeddingManager
from src.vector_store import VectorStore
import logging

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Pattern pour les s√©parateurs
SEPARATOR_PATTERN = re.compile(r'\n\s*\*{4,}\s*\n')


def extract_sections(text: str):
    """Extract sections based on headers"""
    sections = []
    current_section = {"title": "Introduction", "content": ""}
    
    for line in text.split('\n'):
        if line.strip().startswith('#'):
            if current_section["content"].strip():
                sections.append(current_section)
            title = line.strip().lstrip('#').strip()
            current_section = {"title": title, "content": ""}
        else:
            current_section["content"] += line + "\n"
    
    if current_section["content"].strip():
        sections.append(current_section)
    
    # Si pas de sections, cr√©er une section par d√©faut
    if not sections:
        sections = [{"title": "Document Content", "content": text}]
    
    return sections


def chunk_by_separator(text: str):
    """Chunk text by separator patterns"""
    if not text or not text.strip():
        return []
    
    chunks = SEPARATOR_PATTERN.split(text)
    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]
    
    return chunks


def validate_and_reindex():
    """Validate documents and reindex with separator chunking"""
    print("=" * 70)
    print("üîç VALIDATION ET R√âINDEXATION AVEC CHUNKING PAR S√âPARATEURS")
    print("=" * 70)
    
    # 1. V√©rifier que le dossier existe
    docs_path = Path(Config.DOCS_FOLDER)
    if not docs_path.exists():
        print(f"\n‚ùå Dossier non trouv√©: {Config.DOCS_FOLDER}")
        print("Veuillez cr√©er le dossier et ajouter vos fichiers .md ou .txt")
        return False
    
    # 2. Lister les fichiers
    md_files = list(docs_path.glob("*.md")) + list(docs_path.glob("*.txt"))
    
    if not md_files:
        print(f"\n‚ùå Aucun fichier .md ou .txt trouv√© dans {Config.DOCS_FOLDER}")
        return False
    
    print(f"\nüìÑ {len(md_files)} fichier(s) trouv√©(s)")
    
    # 3. Valider chaque fichier
    print("\n" + "=" * 70)
    print("PHASE 1: VALIDATION DES DOCUMENTS")
    print("=" * 70)
    
    valid_files = []
    invalid_files = []
    
    for doc_file in md_files:
        print(f"\nüìñ {doc_file.name}")
        print("-" * 70)
        
        with open(doc_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"  Taille: {len(content)} caract√®res")
        
        # Chercher les s√©parateurs
        separators = SEPARATOR_PATTERN.findall(content)
        separator_count = len(separators)
        expected_chunks = separator_count + 1 if separator_count > 0 else 0
        
        print(f"  S√©parateurs trouv√©s: {separator_count}")
        print(f"  Chunks attendus: {expected_chunks}")
        
        if separator_count > 0:
            print(f"  ‚úÖ VALIDE - Document correctement format√©")
            valid_files.append(doc_file)
            
            # Afficher un exemple de s√©parateur
            if separators:
                print(f"  Exemple de s√©parateur: {repr(separators[0][:20])}")
        else:
            print(f"  ‚ùå INVALIDE - Aucun s√©parateur (****) trouv√©!")
            print(f"  ")
            print(f"  Vos documents doivent contenir des lignes comme:")
            print(f"    ****")
            print(f"    *****")
            print(f"    ******")
            print(f"  ")
            print(f"  Aper√ßu du contenu:")
            print(f"  {content[:300]}")
            invalid_files.append(doc_file)
    
    # 4. R√©sum√© de validation
    print("\n" + "=" * 70)
    print("R√âSUM√â DE VALIDATION")
    print("=" * 70)
    print(f"‚úÖ Fichiers valides: {len(valid_files)}")
    print(f"‚ùå Fichiers invalides: {len(invalid_files)}")
    
    if invalid_files:
        print("\nFichiers invalides:")
        for f in invalid_files:
            print(f"  - {f.name}")
        print("\n‚ö†Ô∏è  Veuillez ajouter des s√©parateurs (****) dans ces fichiers avant de continuer.")
    
    if not valid_files:
        print("\n‚ùå ERREUR: Aucun fichier valide trouv√©!")
        print("Impossible de continuer avec la r√©indexation.")
        return False
    
    # 5. Demander confirmation
    print("\n" + "=" * 70)
    response = input(f"\nüöÄ Continuer avec la r√©indexation de {len(valid_files)} fichier(s) valide(s)? (o/n): ")
    
    if response.lower() != 'o':
        print("‚ùå R√©indexation annul√©e")
        return False
    
    # 6. R√©indexation
    print("\n" + "=" * 70)
    print("PHASE 2: R√âINDEXATION")
    print("=" * 70)
    
    try:
        # Initialiser les composants
        print("\nüîß Initialisation des composants...")
        embedding_manager = EmbeddingManager(Config.EMBEDDING_MODEL)
        vector_store = VectorStore(Config.CHROMA_DB_PATH)
        
        # Cr√©er une nouvelle collection
        print("üì¶ Cr√©ation d'une nouvelle base de donn√©es vectorielle...")
        collection = vector_store.create_collection(reset=True)
        
        all_chunks = []
        all_metadatas = []
        total_chunks = 0
        
        # Traiter chaque fichier valide
        for doc_file in valid_files:
            print(f"\nüìñ Traitement: {doc_file.name}")
            
            with open(doc_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extraire les sections
            sections = extract_sections(content)
            print(f"  Sections trouv√©es: {len(sections)}")
            
            # Chunker chaque section
            for section in sections:
                section_title = section["title"]
                section_content = section["content"]
                
                if not section_content.strip():
                    continue
                
                # Chunking par s√©parateurs
                chunks = chunk_by_separator(section_content)
                
                if not chunks:
                    print(f"  ‚ö†Ô∏è  Section '{section_title}': Aucun chunk cr√©√©")
                    continue
                
                print(f"  Section '{section_title}': {len(chunks)} chunks")
                
                # Ajouter les chunks
                for i, chunk in enumerate(chunks):
                    if not chunk.strip():
                        continue
                    
                    all_chunks.append(chunk)
                    
                    # Cr√©er les m√©tadonn√©es
                    first_line = chunk.split('\n')[0][:100]
                    metadata = {
                        "document": doc_file.stem,
                        "section": section_title,
                        "chunk_index": i,
                        "chunk_preview": first_line,
                        "chunk_length": len(chunk),
                        "source_file": doc_file.stem
                    }
                    all_metadatas.append(metadata)
                    total_chunks += 1
        
        if not all_chunks:
            print("\n‚ùå ERREUR: Aucun chunk cr√©√©!")
            return False
        
        print(f"\n‚úÖ Total de chunks cr√©√©s: {total_chunks}")
        
        # G√©n√©rer les embeddings
        print(f"\nüî¢ G√©n√©ration des embeddings pour {len(all_chunks)} chunks...")
        embeddings = embedding_manager.encode_batch(all_chunks)
        print(f"‚úÖ {len(embeddings)} embeddings g√©n√©r√©s")
        
        # Ajouter √† la base vectorielle
        print("\nüíæ Ajout des chunks √† la base de donn√©es vectorielle...")
        vector_store.add_documents(all_chunks, all_metadatas, embeddings)
        
        # V√©rification finale
        final_count = collection.count()
        print(f"\n‚úÖ Base de donn√©es cr√©√©e avec {final_count} chunks!")
        
        # Test de r√©cup√©ration
        print("\n" + "=" * 70)
        print("PHASE 3: TEST DE R√âCUP√âRATION")
        print("=" * 70)
        
        test_query = "Quels sont vos services?"
        print(f"\nüß™ Requ√™te test: '{test_query}'")
        
        query_embedding = embedding_manager.encode(test_query)
        results = vector_store.query(query_embedding, n_results=3)
        
        if results['documents'] and results['documents'][0]:
            print(f"‚úÖ R√©cup√©ration r√©ussie: {len(results['documents'][0])} chunks")
            
            print("\nüìä Top 3 r√©sultats:")
            for i, (doc, meta, dist) in enumerate(zip(
                results['documents'][0],
                results['metadatas'][0],
                results['distances'][0]
            )):
                print(f"\n  R√©sultat {i+1}:")
                print(f"    Distance: {dist:.4f}")
                print(f"    Document: {meta.get('document', 'N/A')}")
                print(f"    Section: {meta.get('section', 'N/A')}")
                print(f"    Aper√ßu: {doc[:150]}...")
        else:
            print("‚ùå Test √©chou√©: Aucun chunk r√©cup√©r√©!")
            return False
        
        print("\n" + "=" * 70)
        print("‚úÖ R√âINDEXATION TERMIN√âE AVEC SUCC√àS!")
        print("=" * 70)
        print(f"\nüìä Statistiques finales:")
        print(f"  - Fichiers trait√©s: {len(valid_files)}")
        print(f"  - Chunks index√©s: {final_count}")
        print(f"  - Base de donn√©es: {Config.CHROMA_DB_PATH}")
        print(f"\nüöÄ Vous pouvez maintenant d√©marrer votre chatbot!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERREUR durant la r√©indexation: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = validate_and_reindex()
    sys.exit(0 if success else 1)